{"intents": [
        {"tag": "is_on",
        "patterns": ["[]", "array", "for","for each", "foreach","for x in array", "for in", "for (int i = 0; i < n; i++) {a[i] = INT;}", "what time complexity", "time complexity", "time"],
        "responses": ["The time complexity for this code is O(n)"],
        "context": ["time complexity"]
       },
       {"tag": "is_on^2",
        "patterns": ["for {for}","for each for each", "foreach foreach","for x in array for x in array", "for in for in" , "for (int i = 0; i < n; i++) {a[i] = INT;for (int i = 0; i < m; i++) {b[i] = INT;}}", "what time complexity", "time complexity", "time"],
        "responses": ["The time complexity for this code is O(n^2)"],
        "context": ["time complexity"]
       },
       {"tag": "o1_example",
        "patterns": ["what is an example of o(1)", "o(1)", "o(1) example", "o1", "o1 pseudocode"],
        "responses": ["Accessing Array Index (int a = ARR[5];)", "Inserting a node in Linked List","Pushing and Poping on Stack","Insertion and Removal from Queue","Finding out the parent or left/right child of a node in a tree stored in Array","Jumping to Next/Previous element in Doubly Linked List"],
        "context": ["example"]
       },
       {"tag": "on_example",
        "patterns": ["what is an example of o(n)", "o(n)", "o(n) example", "on", "on pseudocode"],
        "responses": ["Traversing an array","Traversing a linked list","Linear Search","Deletion of a specific element in a Linked List (Not sorted)","Comparing two strings"],
        "context": ["example"]
       },
       {"tag": "ologn_example",
        "patterns": ["what is an example of o(log n)", "o(log n)", "o(log n) example", "o log n", "o log n pseudocode"],
        "responses": ["Binary Search","Finding largest/smallest number in a binary search tree","Certain Divide and Conquer Algorithms based on Linear functionality","Calculating Fibonacci Numbers"],
        "context": ["example"]
       },
       {"tag": "onlogn_example",
        "patterns": ["what is an example of o(n log n)", "o(n log n)", "o(n log n) example", "o n log n", "o n log n pseudocode"],
        "responses": ["Merge Sort", "Heap Sort", "Quick Sort"],
        "context": ["example"]
       },
       {"tag": "bubble_pseudocode",
        "patterns": ["bubble sort","what is bubble sort", "bubble", "bubble sort pseudocode", "bubble pseudocode"],
        "responses": ["begin BubbleSort(list)  for all elements of list if list[i] > list[i+1] swap(list[i], list[i+1])end if end for return list    end BubbleSort"],
        "context": ["pseudocode"]
       },
       {"tag": "merge_pseudocode",
        "patterns": ["merge sort","what is merge sort", "merge", "merge sort pseudocode", "merge pseudocode"],
        "responses": ["    step 1: start       step 2: declare array and left, right, mid variable    step 3: perform merge function.        if left > right    return         mid= (left+right)/2        mergesort(array, left, mid)        mergesort(array, mid+1, right)     merge(array, left, mid, right)     step 4: Stop"],
        "context": ["pseudocode"]
       },
       {"tag": "insertion_pseudocode",
        "patterns": ["insertion sort","what is insertion sort", "insertion", "insertion sort pseudocode", "insertion pseudocode"],
        "responses": ["procedure insertionSort( A : array of items )   int holePosition        int valueToInsert       for i = 1 to length(A) inclusive do:    /* select value to be inserted */       valueToInsert = A[i]    holePosition = i        /*locate hole position for the element to be inserted */                while holePosition > 0 and A[holePosition-1] > valueToInsert do:                A[holePosition] = A[holePosition-1]             holePosition = holePosition -1          end while               /* insert the number at hole position */                A[holePosition] = valueToInsert         end for                         end procedure"],
        "context": ["pseudocode"]
       },
       {"tag": "greeting",
        "patterns": ["Hi there", "How are you", "Is anyone there?","Hey","Hola", "Hello", "Good day"],
        "responses": ["Hello, thanks for asking", "Good to see you again", "Hi there, how can I help?"],
        "context": [""]
       },
       {"tag": "goodbye",
        "patterns": ["Bye", "See you later", "Goodbye", "Nice chatting to you, bye", "Till next time"],
        "responses": ["See you!", "Have a nice day", "Bye! Come back again soon."],
        "context": [""]
       },
       {"tag": "thanks",
        "patterns": ["Thanks", "Thank you", "That's helpful", "Awesome, thanks", "Thanks for helping me"],
        "responses": ["Happy to help!", "Any time!", "My pleasure"],
        "context": [""]
       },
       {"tag": "noanswer",
        "patterns": [],
        "responses": ["Sorry, can't understand you. Feel free to message a TA or professor using the links in this site"],
        "context": [""]
       },
        {"tag": "Big_O_explanation",
        "patterns": ["What is big O notation?", "explain big O notation", "explain big O", "O notation"],
        "responses": ["Big-O notation (also called asymptotic growth notation) is a relative representation of the complexity of an algorithm. It shows how an algorithm scales based on input size. We use it to talk about how things scale."],
        "context": ["definition"]
       },
       {"tag": "worst_case",
        "patterns": ["Explain worst case","what does worst case mean"],
        "responses": ["Big-O is often used to make statements about functions that measure the worst case behavior of an algorithm. Worst case analysis gives the maximum number of basic operations that have to be performed during execution of the algorithm. It assumes that the input is in the worst possible state and maximum work has to be done to put things right."],
        "context": ["definition"]
       },
       {"tag": "Ologn_algorithm_examples",
        "patterns": ["What are the most efficient sorts","fastest sort types","O(logn) sort operations"],
        "responses": ["Most efficient sorts are an example of O(log n) operations, such as merge sort. ​It is O(log n) when we do divide and conquer type of algorithms e.g binary search. Another example is quick sort where each time we divide the array into two parts and each time it takes O(N) time to find a pivot element. Hence it N O(log N)"],
        "context": ["example"]
       },
       {"tag": "O_logn_explanation",
        "patterns": ["What does OlogN mean","explain Ologn","O(log n) explanation"],
        "responses": ["O(log n) means for every element", "you're doing something that only needs to look at log N of the elements. This is usually because you know something about the elements that let you make an efficient choice (for example to reduce a search space). The most common attributes of logarithmic running-time function are that: the choice of the next element on which to perform some action is one of several possibilities, and only one will need to be chosen or the elements on which the action is performed are digits of n. "],
        "context": ["explanation"]
       },
       {"tag": "Big_O_purpose",
        "patterns": ["Why do we use Big O notation to compare algorithms?","purpose of big O"],
        "responses": [" It's difficult to determine the exact runtime of an algorithm. It depends on the speed of the computer processor. So instead of talking about the runtime directly, we use Big O Notation to talk about how quickly the runtime grows depending on input size. With Big O Notation, we use the size of the input, which we call n. So we can say things like the runtime grows on the order of the size of the input (O(n)) or on the order of the square of the size of the input (O(n^2)). Our algorithm may have steps that seem expensive when n is small but are eclipsed eventually by other steps as n gets larger. For Big O Notation analysis, we care more about the stuff that grows fastest as the input grows, because everything else is quickly eclipsed as n gets very large."],
        "context": ["explanation"]
       },
       {"tag": "O(n^2)",
        "patterns": ["What exactly would an O(n^2) operation do?","explain O(n^2) operation","O(n^2)"],
        "responses": ["O(n^2) means for every element, you're doing something with every other element, such as comparing them. Bubble sort is an example of this."],
        "context": ["example"]
       },
       {"tag": "O(1)vsO(n)",
        "patterns": ["Explain the difference between O(1) vs O(n) space complexities.","difference between O(1) and O(n)"],
        "responses": ["Let's consider a traversal algorithm for traversing a list. O(1) denotes constant space use: the algorithm allocates the same number of pointers irrespective to the list size. That will happen if we move (reuse) our pointer along the list. In contrast, O(n) denotes linear space use: the algorithm space use grows together with respect to the input size n. That will happen if let's say for some reason the algorithm needs to allocate 'N' pointers (or other variables) when traversing a list."],
        "context": ["explanation"]
       },
       {"tag": "O1_example",
        "patterns": [" Provide an example of O(1) algorithm in code.","O(1) example code","O(1)"],
        "responses": ["Say we have an array of n elements:     int array[n];   If we wanted to access the first (or any) element of the array this would be O(1) since it doesn't matter how big the array is, it always takes the same constant time to get the first item:   x = array[0];"],
        "context": ["example"]
       },
       {"tag": "CSAlgorithm_definition",
        "patterns": ["Explain what is an algorithm in computing?","What is an algorithm"],
        "responses": ["An algorithm is a well-defined computational procedure that take some value as input and generate some value as output. In simple words, it’s a sequence of computational steps that converts input into the output."],
        "context": ["definition"]
       },
       {"tag": "quicksort_explanation",
        "patterns": ["Explain what is Quick Sort algorithm?","explain quick sort","quick sort","what is quick sort"],
        "responses": [" Quick Sort algorithm has the ability to sort list or queries quickly. It is based on the principle of partition exchange sort or Divide and conquer. This type of algorithm occupies less space, and it segregates the list into three main parts.     -Elements less than the Pivot element   -Pivot element  -Elements greater than the Pivot element"],
        "context": ["explanation"]
       },
       {"tag": "time_complexity_explanation",
        "patterns": ["Explain what is time complexity of Algorithms?","explain time complexity", "explain runtime","time complexity"],
        "responses": ["Time complexity of an algorithm indicates the total time needed by the program to run to completion. It is usually expressed by using the big O notation."],
        "context": ["definition"]
       },
       {"tag": "notations",
        "patterns": ["Mention what are the types of Notation used for Time Complexity","explain runtime notations","what are all the notations","notations"],
        "responses": ["The types of Notations used for Time Complexity includes        Big O: It indicates fewer than or the same as <expression>iterations  Big Omega: It indicates more than or same as <expression>iterations   Big Theta: It indicates the same as <expression>iterations     Little Oh: It indicates fewer than <expression>iterations     Little Omega: It indicates more than <expression>iterations"],
        "context": ["explanation"]
       },
       {"tag": "binarysearch_explanation",
        "patterns": ["Explain how binary search works","explain binary search","binary search"],
        "responses": ["In binary search, we compare the key with the item in the middle position of the array. If the key is less than the item searched then it must lie in the lower half of the array, if the key is greater than the item searched than it should be in upper half of the array."],
        "context": ["explanation"]
       },
       {"tag": "binarysearch_in_linkedlist",
        "patterns": ["Explain whether it is possible to use binary search for linked lists","can you binary search linked lists","does binary search work in linked list","binary search","linked list"],
        "responses": ["Since random access is not acceptable in linked list, it is impossible to reach the middle element of O(1) time. Thus, binary search is not possible for linked list."],
        "context": ["explanation"]
       },
       {"tag": "heapsort",
        "patterns": [" Explain what is heap sort","heap sort explanation","what is heap sort","heap sort"],
        "responses": ["Heap-sort can be defined as a comparison based sorting algorithm. It divides its input into the unsorted and sorted region, until it shrinks the unsorted region by eliminating the smallest element and moving that to the sorted region."],
        "context": ["explanation"]
       },
      {"tag": "skiplist",
        "patterns": ["Explain what is Skip list","what is skiplist","skip list"],
        "responses": ["Skip list the method for data structuring, where it allows the algorithm to search, delete and insert elements in a symbol table or dictionary. In a skip list, each element is represented by a node. The search function returns the content of the value related to key. The insert operation associates a specified key with a new value, while the delete function deletes the specified key."],
        "context": ["explanation"]
       },
       {"tag": "insertionsort_space_complexity",
        "patterns": ["Explain what is Space complexity of insertion sort algorithm", "insertion sort space complexity"],
        "responses": ["Insertion sort is an in-place sorting algorithm which means that it requires no extra or little. storage. For insertion sort, it requires only single list elements to be stored out-side the initial data, making the space-complexity 0(1)."],
        "context": ["example"]
       },
       {"tag": "hash",
        "patterns": ["Explain what a Hash Algorithm is and what are they used for","hash algorithm usage","what is hash algorithm","hash algorithm"],
        "responses": ["Hash Algorithm is a hash function that takes a string of any length and decreases it to a unique fixed length string. It is used for password validity, message & data integrity and for many other cryptographic systems."],
        "context": ["explanation"]
       },
       {"tag": "linkedlist_find_loop",
        "patterns": ["Explain how to find whether the linked list has a loop","linked list loop","how to find loop in linked list"],
        "responses": ["To know whether the linked list has a loop, we will take two pointer approach. If we maintain two pointers, and we increase one pointer after processing two nodes and other after processing every node, we are likely to encounter a situation where both the pointer will be pointing to the same node. This will only occur if linked list has a loop."],
        "context": ["explanation"]
       },
       {"tag": "encryption_algorithm",
        "patterns": ["Explain how encryption algorithm works","encryption algorithm","explain encryption"],
        "responses": ["Encryption is the process of converting plaintext into a secret code format referred as Ciphertext. To convert the text, algorithm uses a string of bits referred as keys for calculations. The larger the key, the greater the number of potential patterns for creating cipher text. Most encryption algorithm use codes fixed blocks of input that have length about 64 to 128 bits, while some uses stream method."],
        "context": ["explanation"]
       },
       {"tag": "cryptographic_algorithms",
        "patterns": ["List out some of the commonly used cryptographic algorithms","what are some cryptographic algorithms","encryption algorithms","cryptographic"],
        "responses": ["Some of the commonly used cryptographic algorithms are  3-way   Blowfish        CAST    CMEA    GOST    DES and Triple DES      IDEA    LOKI"],
        "context": ["example"]
       },
       {"tag": "best_vs_worst_case",
        "patterns": ["Explain what is the difference between best case scenario and worst case scenario of an algorithm","best case vs worst case","best case","worst case"],
        "responses": ["Best case scenario: Best case scenario for an algorithm is explained as the arrangement of data for which the algorithm performs best. For example, we take a binary search, for which the best case scenario would be if the target value is at the very center of the data you are searching. The best case time complexity would be 0 (1).   Worst case scenario: It is referred for the worst set of input for a given algorithm. For example quicksort, which can perform worst if you select the largest or smallest element of a sublist for the pivot value. It will cause quicksort to degenerate to O (n2)."],
        "context": ["explanation"]
       },
        {"tag": "Radix_sort",
        "patterns": ["Explain what is Radix Sort algorithm","what is radix sort","explain radix sort","radix sort"],
        "responses": ["Radix sort puts the element in order by comparing the digits of the numbers. It is one of the linear sorting algorithms for integers."],
        "context": ["explanation"]
       },
       {"tag": "recursive_algorithm",
        "patterns": ["Explain what is a recursive algorithm","recursive algorithm","what is recursion"],
        "responses": ["Recursive algorithm is a method of solving a complicated problem by breaking a problem down into smaller and smaller sub-problems until you get the problem small enough that it can be solved easily. Usually, it involves a function calling itself."],
        "context": ["explanation"]
       },
       {"tag": "recursive_laws",
        "patterns": ["Mention what are the three laws of recursion algorithm","how to write a recursive algorithm","recursion rules"],
        "responses": ["All recursive algorithm must follow three laws  It should have a base case      A recursive algorithm must call itself  A recursive algorithm must change its state and move towards the base case"],
        "context": ["explanation"]
       },
       {"tag": "bubble_sort_definition",
        "patterns": ["Explain what is bubble sort algorithm","what is bubble sort","explain bubble sort","bubble sort"],
        "responses": ["Bubble sort algorithm is also referred as sinking sort. In this type of sorting, the list to be sorted out compares the pair of adjacent items. If they are organized in the wrong order, it will swap the values and arrange them in the correct order."],
        "context": ["definition"]
       },
       {"tag": "binarysearch_correctness_example",
        "patterns": ["Write a proof by induction to show the correctness of the binary search code given below:        // Find index of x in sorted array  A[p..r]. Return -1 if x is not in A[p..r].  int binarySearch ( A, p, r, x ): // Pre: A[p..r] is sorted      if p > r then return -1         else    q <-- (p+r)/2   if x < A[q] then        return binarySearch ( A, p, q-1, x)     else if x = A[q] then   return q        else // x > A[q]        return binarySearch ( A, q+1, r, x)"],
        "responses": ["Base Case: Array of size one where both p=r=1 q = 1 if x = A[1] then it will return 1 or else -1 Inductive Case: Let us assume the algorithm works for all array sizes up to k. We have to prove it works for array of size k + one. Both the sub problems should work correctly since their sizes are less then k . The center q calculation and checking works correctly, if x=A[q] returns q or returns the correct solution from the sub problems. Therefore, the algorithm is correct. Hence Proved"],
        "context": ["example"]
       },
       {"tag": "sorting_example_question",
        "patterns": ["Consider sorting n numbers stored in array A by first finding the smallest element of A and exchanging it with the element A[1]. Then find the second smallest element of A, and exchange it with A[2]. Continue in this manner for the first n-1 elements of A. Write pseudocode for this algorithm, which is known as selection sort. What loop invariant does this algorithm maintain? Why does it need to run only the first n-1 elements, rather than for all n-elements? Give the bestcase and worst-case running times of selection sort in Θ-notation."],
        "responses": ["Selection-Sort(A)       n = A.length    For j = 1 to n - 1      smallest = j    For i = j+1 to n        If A[i] < A[smallest]   smallest = i    Exchange A[j] with A[smallest]  The algorithm maintains the loop invariant that at the start of each iteration of the outer for loop, the subarray A[1…j-1] consists of the j-1 smallest elements in the array A[1…n], and this subarray is in sorted order. After the first n-1 elements, the subarray A[1..n-1] contains the smallest n-1 elements, sorted, and therefor element A[n] must be the largest element. The running time of the algorithm is O(n^2) for all cases."],
        "context": ["example"]
       },
       {"tag": "O(nlgn)_algorithm_example",
        "patterns": ["Describe a O(n lg n) –time algorithm that, given a set S of n integers and another integer x, determines whether or not there exist two elements in S whose sum is exactly x"],
        "responses": ["The following algorithm solves the problem:     1. Sort the elements in S       2. Form the set S’ = {z : z = x - y for some y subset of S}     3. Sort the elements in S’      4. Merge the sorted sets S and S’       5. There exists two elements in S whose sum is exactly x if and only if the same value appears in consecutive positions in the merged output.   To justify the claim in step 4, first observe that if any value appears twice in the merged output, it must appear in consecutive positions. Thus, we can restate the condition in step 5 as there exists two elements in S whose sum is exactly x if and only if the same value appears twice in the merged output."],
        "context": ["algorithm"]
       },
       {"tag": "selction sort worst case time complexity",
        "patterns": ["what is the time complexity of selection sort", "what is the big o of selection sort", "what is the worst case time of selection sort"],
        "responses": ["O(n^2)"],
        "context": ["time complexity", "worst case", "big o"]
       },
       {"tag": "selction sort best case time complexity",
        "patterns": ["what is the best case time complexity of selection sort", "what is the big omega of selection sort", "what is the best case time of selection sort"],
        "responses": ["Ω(n^2)"],
        "context": ["time complexity", "best case", "big omega"]
       },
       {"tag": "bubble sort worst case time complexity",
        "patterns": ["what is the time complexity of bubble sort", "what is the big o of bubble sort", "what is the worst case time of bubble sort"],
        "responses": ["O(n^2)"],
        "context": ["time complexity", "worst case", "big o"]
       },
       {"tag": "bubble sort best case time complexity",
        "patterns": ["what is the best case time complexity of bubble sort", "what is the big omega of bubble sort", "what is the best case time of bubble sort"],
        "responses": ["Ω(n)"],
        "context": ["time complexity", "best case", "big omega"]
       },
       {"tag": "insertion sort worst case time complexity",
        "patterns": ["what is the time complexity of insertion sort", "what is the big o of insertion sort", "what is the worst case time of insertion sort"],
        "responses": ["O(n^2)"],
        "context": ["time complexity", "worst case", "big o"]
       },
       {"tag": "insertion sort best case time complexity",
        "patterns": ["what is the best case time complexity of insertion sort", "what is the big omega of insertion sort", "what is the best case time of insertion sort"],
        "responses": ["Ω(n)"],
        "context": ["time complexity", "best case", "big omega"]
       },
       {"tag": "heap sort worst case time complexity",
        "patterns": ["what is the time complexity of heap sort", "what is the big o of heap sort", "what is the worst case time of heap sort"],
        "responses": ["O(n log n)"],
        "context": ["time complexity", "worst case", "big o"]
       },
       {"tag": "heap sort best case time complexity",
        "patterns": ["what is the best case time complexity of heap sort", "what is the big omega of heap sort", "what is the best case time of heap sort"],
        "responses": ["Ω(n log n)"],
        "context": ["time complexity", "best case", "big omega"]
       },
       {"tag": "quick sort worst case time complexity",
        "patterns": ["what is the time complexity of quick sort", "what is the big o of quick sort", "what is the worst case time of quick sort"],
        "responses": ["O(n^2)"],
        "context": ["time complexity", "worst case", "big o"]
       },
       {"tag": "quick sort best case time complexity",
        "patterns": ["what is the best case time complexity of quick sort", "what is the big omega of quick sort", "what is the best case time of quick sort"],
        "responses": ["Ω(n log n)"],
        "context": ["time complexity", "best case", "big omega"]
       },
       {"tag": "merge sort worst case time complexity",
        "patterns": ["what is the time complexity of merge sort", "what is the big o of merge sort", "what is the worst case time of merge sort"],
        "responses": ["O(n log n)"],
        "context": ["time complexity", "worst case", "big o"]
       },
       {"tag": "merge sort best case time complexity",
        "patterns": ["what is the best case time complexity of merge sort", "what is the big omega of merge sort", "what is the best case time of merge sort"],
        "responses": ["Ω(n log n)"],
        "context": ["time complexity", "best case", "big omega"]
       },
       {"tag": "bucket sort worst case time complexity",
        "patterns": ["what is the time complexity of bucket sort", "what is the big o of bucket sort", "what is the worst case time of bucket sort"],
        "responses": ["O(n^2)"],
        "context": ["time complexity", "worst case", "big o"]
       },
       {"tag": "bucket sort best case time complexity",
        "patterns": ["what is the best case time complexity of bucket sort", "what is the big omega of bucket sort", "what is the best case time of bucket sort"],
        "responses": ["Ω(n + k)"],
        "context": ["time complexity", "best case", "big omega"]
       },
       {"tag": "radix sort worst case time complexity",
        "patterns": ["what is the time complexity of radix sort", "what is the big o of radix sort", "what is the worst case time of radix sort"],
        "responses": ["O(nk)"],
        "context": ["time complexity", "worst case", "big o"]
       },
       {"tag": "radix sort best case time complexity",
        "patterns": ["what is the best case time complexity of radix sort", "what is the big omega of radix sort", "what is the best case time of radix sort"],
        "responses": ["Ω(nk)"],
        "context": ["time complexity", "best case", "big omega"]
       }
       ,
       {"tag": "count sort worst case time complexity",
        "patterns": ["what is the time complexity of count sort", "what is the big o of count sort", "what is the worst case time of count sort"],
        "responses": ["O(n + k)"],
        "context": ["time complexity", "worst case", "big o"]
       },
       {"tag": "count sort best case time complexity",
        "patterns": ["what is the best case time complexity of count sort", "what is the big omega of count sort", "what is the best case time of count sort"],
        "responses": ["Ω(n + k)"],
        "context": ["time complexity", "best case", "big omega"]
       },
       {"tag": "shell sort worst case time complexity",
        "patterns": ["what is the time complexity of shell sort", "what is the big o of shell sort", "what is the worst case time of shell sort"],
        "responses": ["O(n^2"],
        "context": ["time complexity", "worst case", "big o"]
       },
       {"tag": "shell sort best case time complexity",
        "patterns": ["what is the best case time complexity of shell sort", "what is the big omega of shell sort", "what is the best case time of shell sort"],
        "responses": ["Ω(n log n)"],
        "context": ["time complexity", "best case", "big omega"]
       },
       {"tag": "tim sort worst case time complexity",
        "patterns": ["what is the time complexity of tim sort", "what is the big o of tim sort", "what is the worst case time of tim sort"],
        "responses": ["O(n log n)"],
        "context": ["time complexity", "worst case", "big o"]
       },
       {"tag": "tim sort best case time complexity",
        "patterns": ["what is the best case time complexity of tim sort", "what is the big omega of tim sort", "what is the best case time of tim sort"],
        "responses": ["Ω(n)"],
        "context": ["time complexity", "best case", "big omega"]
       },
       {"tag": "tree sort worst case time complexity",
        "patterns": ["what is the time complexity of tree sort", "what is the big o of tree sort", "what is the worst case time of tree sort"],
        "responses": ["O(n^2)"],
        "context": ["time complexity", "worst case", "big o"]
       },
       {"tag": "tree sort best case time complexity",
        "patterns": ["what is the best case time complexity of tree sort", "what is the big omega of tree sort", "what is the best case time of tree sort"],
        "responses": ["Ω(n log n)"],
        "context": ["time complexity", "best case", "big omega"]
       },
       {"tag": "cube sort worst case time complexity",
        "patterns": ["what is the time complexity of cube sort", "what is the big o of cube sort", "what is the worst case time of cube sort"],
        "responses": ["O(n log n)"],
        "context": ["time complexity", "worst case", "big o"]
       },
       {"tag": "cube sort best case time complexity",
        "patterns": ["what is the best case time complexity of cube sort", "what is the big omega of cube sort", "what is the best case time of cube sort"],
        "responses": ["Ω(n)"],
        "context": ["time complexity", "best case", "big omega"]
       }
   ]
}
